# 🎓 Enable-Ed: Inclusive Learning Platform

**Enable-Ed** is an online learning platform developed as our **final year B.Tech CSE project**.  
It is designed to empower students with disabilities by integrating **multi-sensory learning resources** such as **sign language translation, speech-to-text captions, text-to-speech narration, and image description**.  
The platform ensures accessibility, inclusivity, and independence in learning.

---

## 🌟 Key Features
- 👂 **Sign Language Translation** → Supports learners with hearing impairments.  
- 🎤 **Speech-to-Text Subtitles** → Converts video/audio content into captions.  
- 🗣 **Text-to-Speech Narration** → Reads out text and content for visually impaired learners.  
- 🖼 **Image Description Module** → Generates and narrates descriptions for images using NLP + Hugging Face API.  
- 🧑‍🎓 **Self-Paced & Inclusive Learning** → Encourages independence and engagement.  

---

## 🛠 Tech Stack
- **Frontend:** HTML, CSS, JavaScript  
- **Backend:** Python (Django Framework), Natural Language Processing  
- **Database:** SQLite3  
- **APIs & Tools:** Hugging Face API, gTTS (Google Text-to-Speech)  

---
## 📂 Project Structure
Enable-Ed/
├── backend/ # Django backend code
├── frontend/ # HTML, CSS, JS (UI)
├── docs/ # Reports, design diagrams
├── screenshots/ # App screenshots
├── package.json # Dependencies (if Node.js is used in frontend)
├── requirements.txt # Python dependencies (for backend)
├── .gitignore
└── README.md

---

## 📖 Project Abstract

Enable-Ed is a socially significant project aimed at bridging the gap in digital learning for students with disabilities.
It provides customizable accessibility features to support learners with hearing, visual, and speech impairments.
By combining sign language translation, subtitles, text-to-speech, and image descriptions, the platform ensures that every learner, regardless of ability, can access quality education.

## 📌 Future Scope

Integrate AI-driven adaptive learning for personalized content.
Add real-time sign language generation using AI models.
Extend accessibility features to mobile applications.
Multi-language support for subtitles and narration.
